import streamlit as st
import cv2
import numpy as np
from PIL import Image
import tempfile
import time
import os
from config.logging_config import setup_logging
from models.model_loader import load_model
from models.model_tester import test_model_inference
from utils.image_processor import process_image
import torch
from ultralytics import YOLO
import onnxruntime as ort
import pandas as pd
from utils.video_frame_utils import record_video, extract_frames
import yaml
import hashlib

# ========== å·¥å…·å‡½æ•° =========
def get_image_hash(image):
    """è·å–å›¾ç‰‡å†…å®¹çš„å“ˆå¸Œå€¼ï¼Œç”¨äºå»é‡"""
    img_bytes = image.tobytes()
    return hashlib.md5(img_bytes).hexdigest()

# ========== æ—¥å¿—é…ç½® =========
logger = setup_logging()

# ========== é¡µé¢ä¸æ ·å¼ =========
st.set_page_config(
    page_title="ç²®é£Ÿè´¨é‡æ£€æµ‹å¹³å°",
    page_icon="ğŸŒ½",
    layout="wide"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    :root {
        --primary-color: #4CAF50; /* Green */
        --secondary-color: #E8F5E9; /* Light Green */
        --accent-color: #FFC107; /* Amber */
        --background-color: #FFFFFF; /* White */
    }
    body { color: var(--primary-color); background-color: var(--background-color);}
    h1, h2, h3 { color: var(--primary-color);}
    .stButton > button {
        background-color: var(--accent-color);
        color: white;
        border: none;
        border-radius: 5px;
        padding: 0.5rem 1rem;
    }
    .stTextInput>label, .stNumberInput>label { color: var(--primary-color);}
    .streamlit-expanderHeader { color: var(--primary-color);}
</style>
""", unsafe_allow_html=True)

# ========== æ ‡é¢˜ä¸ä»‹ç» =========
st.title("ğŸŒ½ ç²®é£Ÿè´¨é‡æ£€æµ‹")
st.markdown("æœ¬å¹³å°åŸºäºæ·±åº¦å­¦ä¹ æŠ€æœ¯ï¼Œèƒ½å¤Ÿè‡ªåŠ¨æ£€æµ‹ç‰ç±³ä¸­çš„åç²’å’Œæ‚è´¨ï¼ŒåŠ©åŠ›ç‰ç±³å“è´¨ç®¡ç†å’Œç­›é€‰ã€‚")

# ========== ä¾§è¾¹æ ï¼šæ¨¡å‹è®¾ç½® =========
with st.sidebar:
    st.header("æ£€æµ‹æ¨¡å‹è®¾ç½®")
    DEFAULT_MODEL_PATH = 'model/best.pt'
    default_model_exists = os.path.exists(DEFAULT_MODEL_PATH)

    if default_model_exists:
        st.info(f"æ£€æµ‹åˆ°é»˜è®¤æ¨¡å‹: {DEFAULT_MODEL_PATH}")
    else:
        st.warning(f"æœªæ‰¾åˆ°é»˜è®¤æ¨¡å‹: {DEFAULT_MODEL_PATH}")

    model_choice = st.radio("é€‰æ‹©æ¨¡å‹æ¥æº", ["é»˜è®¤æ¨¡å‹", "ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹"])
    model_file = None
    model_type = None

    if model_choice == "é»˜è®¤æ¨¡å‹" and default_model_exists:
        try:
            model_file = open(DEFAULT_MODEL_PATH, 'rb')
            file_ext = os.path.splitext(DEFAULT_MODEL_PATH)[1].lower()
            model_type = "ONNX" if file_ext == '.onnx' else "PyTorch"
            st.success("å·²é€‰æ‹©é»˜è®¤æ¨¡å‹")
        except Exception as e:
            st.error(f"æ— æ³•åŠ è½½é»˜è®¤æ¨¡å‹: {e}")
            model_file = None
    elif model_choice == "ä¸Šä¼ è‡ªå®šä¹‰æ¨¡å‹":
        model_file = st.file_uploader("ä¸Šä¼ æ¨¡å‹æ–‡ä»¶", type=["pt", "pth", "onnx"])
        if model_file:
            file_ext = os.path.splitext(model_file.name)[1].lower()
            default_model_type = "ONNX" if file_ext == '.onnx' else "PyTorch"
            model_type = st.selectbox(
                "æ¨¡å‹ç±»å‹",
                ["PyTorch", "TorchScript", "ONNX"],
                index=["PyTorch", "TorchScript", "ONNX"].index(default_model_type)
            )
            st.success(f"å·²ä¸Šä¼ æ¨¡å‹: {model_file.name}")
        else:
            st.info("è¯·ä¸Šä¼ æ¨¡å‹æ–‡ä»¶")
    else:
        st.info("è¯·é€‰æ‹©æ¨¡å‹æ¥æº")

    # åªæœ‰é€‰æ‹©æ¨¡å‹åæ‰æ˜¾ç¤ºé«˜çº§è®¾ç½®
    if model_file and model_type:
        confidence_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼", min_value=0.0, max_value=1.0, value=0.6, step=0.05
        )
        from utils.image_processor import LABELS
        with st.expander("é«˜çº§è®¾ç½®"):
            draw_bbox = st.checkbox("æ˜¾ç¤ºè¾¹ç•Œæ¡†", value=True)
            draw_label = st.checkbox("æ˜¾ç¤ºç±»åˆ«åç§°", value=True)
            draw_confidence = st.checkbox("æ˜¾ç¤ºç½®ä¿¡åº¦", value=True)
            line_thickness = st.slider("è¾¹ç•Œæ¡†çº¿æ¡ç²—ç»†", min_value=1, max_value=10, value=2)
            st.markdown("**å„ç±»åˆ«æ ‡è®°é¢œè‰²**")
            if "detection_colors" not in st.session_state or len(st.session_state.detection_colors) != len(LABELS):
                st.session_state.detection_colors = ["#FF0000", "#00FF00", "#0000FF", "#FF00FF", "#FFFF00", "#00FFFF", "#FFA500", "#800080", "#008000", "#FF69B4"]  # çº¢ã€ç»¿ã€è“ã€ç´«ã€é»„ã€é’ã€æ©™ã€ç´«ã€æ·±ç»¿ã€ç²‰
            for idx, label in enumerate(LABELS):
                st.session_state.detection_colors[idx] = st.color_picker(
                    f"{label} æ ‡è®°é¢œè‰²", st.session_state.detection_colors[idx], key=f"color_{idx}"
                )
            detection_colors = st.session_state.detection_colors

    st.header("å…³äº")
    st.info("""
    æœ¬å¹³å°ä¸“ä¸ºç‰ç±³åç²’å’Œæ‚è´¨æ£€æµ‹è®¾è®¡ï¼Œæ”¯æŒå¤šç§å›¾ç‰‡æ ¼å¼ã€‚
    ä¸Šä¼ ç‰ç±³å›¾ç‰‡åï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ£€æµ‹å¹¶æ ‡è®°å‡ºå„ç±»åç²’å’Œæ‚è´¨ã€‚
    """)

# ========== æ—¥å¿—ç›¸å…³å‡½æ•° =========
def log_event(event):
    """è®°å½•æ“ä½œæ­¥éª¤å’Œæ—¶é—´"""
    if 'log_data' not in st.session_state:
        st.session_state.log_data = {
            'åºå·': [],
            'æ“ä½œæ­¥éª¤': [],
            'æ‰§è¡Œæ—¶é—´': []
        }
    st.session_state.log_data['åºå·'].append(len(st.session_state.log_data['åºå·']) + 1)
    st.session_state.log_data['æ“ä½œæ­¥éª¤'].append(event)
    st.session_state.log_data['æ‰§è¡Œæ—¶é—´'].append(time.strftime("%Y-%m-%d %H:%M:%S"))

def show_log_table():
    """æ˜¾ç¤ºæ“ä½œæ—¥å¿—è¡¨æ ¼"""
    if 'log_data' in st.session_state and st.session_state.log_data['åºå·']:
        st.markdown("""
        <style>
        .corn-table-header {
            background: linear-gradient(45deg, #a8e063 0%, #56ab2f 100%); /* Green gradient */
            color: #ffffff;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
            font-size: 1.2rem;
            font-weight: 600;
            text-align: center;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        [data-testid="stDataFrame"] > div {
            background: #e8f5e9; /* Light green */
            padding: 1rem;
            border-radius: 10px;
            box_shadow: 0 2px 8px rgba(76, 175, 80, 0.15); /* Green shadow */
        }
        [data-testid="stDataFrame"] div[data-testid="stHorizontalBlock"] {
            background: white;
            margin: 0.2rem 0;
            border-radius: 5px;
            transition: transform 0.2s ease;
        }
        [data-testid="stDataFrame"] div[data-testid="stHorizontalBlock"]:hover {
            transform: translateX(5px);
            background: #f0fdf0; /* Lighter green on hover */
        }
        [data-testid="stDataFrame"] div[data-testid="stHorizontalBlock"] > div:last-child {
            font-family: monospace;
            color: #388E3C; /* Darker green */
        }
        [data-testid="stDataFrame"] div[data-testid="stHorizontalBlock"] > div:first-child {
            font-weight: 600;
            color: #1B5E20; /* Even darker green */
        }
        </style>
        """, unsafe_allow_html=True)
        st.markdown('<div class="corn-table-header">ğŸŒ½æ“ä½œæ­¥éª¤è®°å½•</div>', unsafe_allow_html=True)
        df = pd.DataFrame(st.session_state.log_data)
        st.dataframe(
            df,
            use_container_width=True,
            hide_index=True,
            column_config={
                "åºå·": st.column_config.NumberColumn(
                    "åºå·", help="æ“ä½œæ­¥éª¤åºå·", format="%d", width="small"
                ),
                "æ“ä½œæ­¥éª¤": st.column_config.TextColumn(
                    "æ“ä½œæ­¥éª¤", help="æ‰§è¡Œçš„å…·ä½“æ“ä½œ", width="medium"
                ),
                "æ‰§è¡Œæ—¶é—´": st.column_config.TextColumn(
                    "æ‰§è¡Œæ—¶é—´", help="æ“ä½œæ‰§è¡Œçš„å…·ä½“æ—¶é—´", width="medium"
                )
            }
        )

def show_category_table(label_counts=None):
    """æ˜¾ç¤ºç¾é£Ÿç±»åˆ«ç»Ÿè®¡è¡¨"""
    with open("data.yaml", "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)
    categories = data["names"]
    cn_categories = data.get("cn_names", categories)
    df_data = []
    for i, cat in enumerate(categories):
        cn_cat = cn_categories[i] if i < len(cn_categories) else cat
        quantity = 0
        if label_counts and cn_cat in label_counts:
            quantity = label_counts[cn_cat]
        df_data.append([cn_cat, quantity])

    df = pd.DataFrame(df_data, columns=["ç±»åˆ«", "æ•°é‡"])

    st.markdown("### ç‰ç±³åç²’å’Œæ‚è´¨ç»Ÿè®¡è¡¨")
    st.dataframe(
        df,
        use_container_width=True,
        hide_index=True,
        column_config={
            "ç±»åˆ«": st.column_config.TextColumn("ç±»åˆ«", width="medium"),
            "æ•°é‡": st.column_config.NumberColumn("æ•°é‡", format="%d", width="small"),
        }
    )

# ========== Session State åˆå§‹åŒ– =========
if 'log_data' not in st.session_state:
    st.session_state.log_data = {'åºå·': [], 'æ“ä½œæ­¥éª¤': [], 'æ‰§è¡Œæ—¶é—´': []}
if 'latest_label_counts' not in st.session_state:
    st.session_state.latest_label_counts = None

# ========== æ¨¡å‹åŠ è½½ =========
if 'loaded_model' not in st.session_state or 'loaded_model_type' not in st.session_state:
    if model_file and model_type:
        log_event(f"åŠ è½½æ¨¡å‹: {model_type}")
        st.session_state.loaded_model = load_model(model_file, model_type)
        st.session_state.loaded_model_type = model_type
        if st.session_state.loaded_model and test_model_inference(st.session_state.loaded_model, model_type):
            log_event("æ¨¡å‹æ¨ç†æµ‹è¯•é€šè¿‡")
        else:
            log_event("æ¨¡å‹æ¨ç†æµ‹è¯•æœªé€šè¿‡")
    else:
        st.session_state.loaded_model = None
        st.session_state.loaded_model_type = None

# ========== ä¸»ç•Œé¢å¸ƒå±€ =========
col1, col2 = st.columns([1, 1])

with col1:
    num_per_row = 4
    status_message = st.empty()

    st.subheader("1. ä¸Šä¼ æ–‡ä»¶")
    uploaded_media = st.file_uploader(
        "é€‰æ‹©å›¾ç‰‡(jpg, png)æˆ–è§†é¢‘(mp4, mov, avi)",
        type=["jpg", "jpeg", "png", "bmp", "mp4", "mov", "avi"],
        accept_multiple_files=True,
        label_visibility="collapsed"
    )

    if uploaded_media:
        for medium in uploaded_media:
            file_ext = os.path.splitext(medium.name)[1].lower()
            if file_ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                image = Image.open(medium)
                img_hash = get_image_hash(image)
                if "image_hashes" not in st.session_state:
                    st.session_state.image_hashes = set()
                if img_hash not in st.session_state.image_hashes:
                    img_path = os.path.join(tempfile.gettempdir(), f"upload_{int(time.time())}_{medium.name}")
                    image.save(img_path)
                    if "frame_paths" not in st.session_state:
                        st.session_state.frame_paths = []
                    st.session_state.frame_paths.append(img_path)
                    st.session_state.image_hashes.add(img_hash)
                    log_event(f"ä¸Šä¼ å›¾ç‰‡æˆåŠŸ: {medium.name}")
                else:
                    log_event(f"å›¾ç‰‡ {medium.name} å·²å­˜åœ¨ï¼Œè·³è¿‡")
            elif file_ext in ['.mp4', '.mov', '.avi']:
                tfile = tempfile.NamedTemporaryFile(delete=False, suffix=file_ext)
                tfile.write(medium.read())
                video_path = tfile.name
                log_event(f"ä¸Šä¼ è§†é¢‘æˆåŠŸ: {medium.name}")
                with st.spinner(f"æ­£åœ¨ä» {medium.name} æŠ½å¸§..."):
                    frame_paths = extract_frames(video_path, medium.name, time_interval_seconds=2, save_dir='frames')
                if "frame_paths" not in st.session_state:
                    st.session_state.frame_paths = []
                st.session_state.frame_paths.extend([p for p in frame_paths if p not in st.session_state.frame_paths])
                log_event(f"ä» {medium.name} æŠ½å¸§å®Œæˆï¼Œå…±æŠ½å– {len(frame_paths)} å¼ å›¾ç‰‡")
        status_message.success("æ–‡ä»¶å¤„ç†å®Œæˆï¼Œè¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹é¢„è§ˆå¹¶å¼€å§‹è¯†åˆ«ã€‚")

    st.subheader("2. ä½¿ç”¨æ‘„åƒå¤´")
    use_camera = st.checkbox("å¼€å¯æ‘„åƒå¤´")
    if use_camera:
        camera_img = st.camera_input("ç‚¹å‡»æ‹ç…§")
        if camera_img:
            image = Image.open(camera_img)
            img_hash = get_image_hash(image)
            if "image_hashes" not in st.session_state:
                st.session_state.image_hashes = set()
            if img_hash not in st.session_state.image_hashes:
                img_path = os.path.join(tempfile.gettempdir(), f"upload_{int(time.time())}_camera.png")
                image.save(img_path)
                if "frame_paths" not in st.session_state:
                    st.session_state.frame_paths = []
                st.session_state.frame_paths.append(img_path)
                st.session_state.image_hashes.add(img_hash)
                log_event(f"æ‘„åƒå¤´æ‹æ‘„æˆåŠŸ")
                status_message.success("ç…§ç‰‡å·²æ·»åŠ ï¼Œè¯·åœ¨ä¸‹æ–¹æŸ¥çœ‹é¢„è§ˆå¹¶å¼€å§‹è¯†åˆ«ã€‚")
            else:
                status_message.info("è¯¥ç…§ç‰‡å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤æ·»åŠ ã€‚")

    st.subheader("3. å…¶ä»–æ–¹å¼")
    remote_video_url = st.text_input('è¾“å…¥è¿œç¨‹è§†é¢‘æµURL (RTSP, RTMP, HTTP)')
    if st.button('å¤„ç†5ç§’è¿œç¨‹è§†é¢‘'):
        if remote_video_url:
            log_event(f"å¼€å§‹å¤„ç†è¿œç¨‹è§†é¢‘æµ: {remote_video_url}")
            with st.spinner('æ­£åœ¨å½•åˆ¶å’ŒæŠ½å¸§...'):
                video_path = record_video(source=remote_video_url, output_path='remote_video.mp4', duration=5)
            log_event("è¿œç¨‹è§†é¢‘å½•åˆ¶å®Œæˆï¼Œå¼€å§‹æŠ½å¸§")
            st.video(video_path)
            with st.spinner("æ­£åœ¨æŠ½å¸§..."):
                frame_paths = extract_frames(video_path, 'remote_video', time_interval_seconds=2, save_dir='frames')
            if "frame_paths" not in st.session_state:
                st.session_state.frame_paths = []
            st.session_state.frame_paths.extend([p for p in frame_paths if p not in st.session_state.frame_paths])
            status_message.success(f"æŠ½å– {len(frame_paths)} å¸§ï¼Œç­‰å¾…è¯†åˆ«...")
            log_event(f"æŠ½å¸§å®Œæˆï¼Œå…±æŠ½å– {len(frame_paths)} å¼ å›¾ç‰‡")
        else:
            st.warning('è¯·è¾“å…¥æœ‰æ•ˆçš„è§†é¢‘æµURL')

    if st.button("å½•åˆ¶5ç§’è§†é¢‘", key="record_video_btn"):
        log_event("å¼€å§‹å½•åˆ¶è§†é¢‘")
        with st.spinner("æ­£åœ¨å½•åˆ¶è§†é¢‘..."):
            video_path = record_video(output_path='output.mp4', duration=5, fps=20)
        log_event("è§†é¢‘å½•åˆ¶å®Œæˆï¼Œå¼€å§‹æŠ½å¸§")
        st.video(video_path)
        with st.spinner("æ­£åœ¨æŠ½å¸§..."):
            frame_paths = extract_frames(video_path, 'recorded_video', time_interval_seconds=2, save_dir='frames')
        if "frame_paths" not in st.session_state:
            st.session_state.frame_paths = []
        st.session_state.frame_paths.extend([p for p in frame_paths if p not in st.session_state.frame_paths])
        status_message.success(f"æŠ½å– {len(frame_paths)} å¸§ï¼Œç­‰å¾…è¯†åˆ«...")
        log_event(f"æŠ½å¸§å®Œæˆï¼Œå…±æŠ½å– {len(frame_paths)} å¼ å›¾ç‰‡")

    if st.session_state.get("frame_paths"):
        st.session_state.frame_paths = list(dict.fromkeys(st.session_state.frame_paths))
        st.markdown("--- ")
        st.markdown("#### å¾…è¯†åˆ«å›¾ç‰‡é¢„è§ˆ")
        all_preview = st.session_state.frame_paths

        def show_preview_grid(path_list):
            rows = (len(path_list) + num_per_row - 1) // num_per_row
            for row in range(rows):
                cols = st.columns(num_per_row)
                for col in range(num_per_row):
                    idx = row * num_per_row + col
                    if idx < len(path_list):
                        frame_path = path_list[idx]
                        try:
                            img = Image.open(frame_path)
                            with cols[col]:
                                st.image(img, caption=os.path.basename(frame_path), use_column_width=True)
                        except Exception as e:
                            with cols[col]:
                                st.warning(f"æ— æ³•é¢„è§ˆå›¾ç‰‡: {frame_path}ï¼Œé”™è¯¯ä¿¡æ¯: {e}")

        preview_paths = all_preview[:num_per_row]
        show_preview_grid(preview_paths)
        more_paths = all_preview[num_per_row:]
        if more_paths:
            with st.expander(f"æŸ¥çœ‹æ›´å¤šï¼ˆå…± {len(more_paths)} å¼ ï¼‰"):
                show_preview_grid(more_paths)

        if st.button("å¼€å§‹è¯†åˆ«", key="start_detect_btn"):
            status_message.info("æ­£åœ¨è¯†åˆ«ä¸­...")
            from collections import Counter
            from utils.image_processor import get_label
            total_label_counts = Counter()
            result_images = []
            start_time = time.time()
            log_event(f"å¼€å§‹è¯†åˆ«ï¼Œå…± {len(st.session_state.frame_paths)} å¼ å›¾ç‰‡")

            for frame_path in st.session_state.frame_paths:
                image = Image.open(frame_path)
                img_array = np.array(image)
                log_event(f"å¤„ç†å›¾ç‰‡: {os.path.basename(frame_path)}")
                if img_array.shape[2] == 4:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGBA2RGB)
                    log_event("å›¾ç‰‡é€šé“ç”±RGBAè½¬ä¸ºRGB")
                else:
                    img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR)
                    log_event("å›¾ç‰‡é€šé“ç”±RGBè½¬ä¸ºBGR")
                if st.session_state.loaded_model and st.session_state.loaded_model_type:
                    result_img, filtered_class_ids = process_image(
                        img_array, st.session_state.loaded_model, st.session_state.loaded_model_type,
                        confidence_threshold, detection_colors,
                        draw_bbox, draw_label, draw_confidence, line_thickness
                    )
                    result_images.append((result_img, os.path.basename(frame_path)))
                    if len(filtered_class_ids) > 0:
                        label_names = [get_label(cls_id) for cls_id in filtered_class_ids]
                        label_counts = Counter(label_names)
                        total_label_counts += label_counts
                        log_event(f"{os.path.basename(frame_path)} è¯†åˆ«æˆåŠŸ: {dict(label_counts)}")
                    else:
                        log_event(f"{os.path.basename(frame_path)} æœªè¯†åˆ«åˆ°åç²’æˆ–æ‚è´¨")

            end_time = time.time()
            process_time = end_time - start_time
            st.session_state.latest_label_counts = total_label_counts
            log_event(f"è¯†åˆ«ç»Ÿè®¡å®Œæˆ: {dict(total_label_counts)}ï¼Œå¤„ç† {len(st.session_state.frame_paths)} å¼ å›¾ç‰‡ï¼Œå…±è€—æ—¶ {process_time:.2f} ç§’")
            status_message.success("è¯†åˆ«å®Œæˆï¼")

            st.markdown("#### è¯†åˆ«ç»“æœé¢„è§ˆ")
            all_results = result_images

            def show_image_grid(image_list, caption_prefix="è¯†åˆ«ç»“æœ"):
                rows = (len(image_list) + num_per_row - 1) // num_per_row
                for row in range(rows):
                    cols = st.columns(num_per_row)
                    for col in range(num_per_row):
                        idx = row * num_per_row + col
                        if idx < len(image_list):
                            img_arr, fname = image_list[idx]
                            with cols[col]:
                                st.image(
                                    cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB),
                                    caption=f"{caption_prefix}: {fname}",
                                    use_column_width=True
                                )

            preview_results = all_results[:num_per_row]
            show_image_grid(preview_results)
            more_results = all_results[num_per_row:]
            if more_results:
                with st.expander(f"æŸ¥çœ‹æ›´å¤šè¯†åˆ«ç»“æœï¼ˆå…± {len(more_results)} å¼ ï¼‰"):
                    show_image_grid(more_results)

with col2:
    st.subheader("æ“ä½œæ—¥å¿—")
    if 'log_data' in st.session_state:
        show_log_table()
    else:
        st.info("æš‚æ— æ“ä½œæ—¥å¿—è®°å½•")

# ========== åº•éƒ¨ç»Ÿè®¡è¡¨ =========
st.markdown("---")
show_category_table(st.session_state.latest_label_counts)

